{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759a7ac6",
   "metadata": {},
   "source": [
    "# Task 0: Getting access to key files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b97b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!cp drive/MyDrive/larsoft_workshop_files/*.py .\n",
    "!cp drive/MyDrive/larsoft_workshop_files/*.pt .\n",
    "!cp drive/MyDrive/larsoft_workshop_files/*.gz .\n",
    "!tar xzf images.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9407d48f",
   "metadata": {},
   "source": [
    "# Task 1: Transfer learning for neutral current interaction classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b6136a",
   "metadata": {},
   "source": [
    "We'll start by importing all of the Python modules required for this notebook - there are numerous other modules used by supporting code, but we'll ignore those here. We only require direct  access to tools to allow us to copy model state, time our training runs, run various torch code and construct a ResNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8900e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, time, torch, torchvision as tv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82597c50",
   "metadata": {},
   "source": [
    "The files below come from the linked Google Drive and provide custom code to support these tutorials. If you're interested, feel free to look through them and ask questions about what they do, but a detailed understanding shouldn't be necessary for this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import *\n",
    "from helpers import *\n",
    "from model_utils import *\n",
    "from training_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d7f967",
   "metadata": {},
   "source": [
    "The model we'll be using is based on a ResNet18 CNN. PyTorch already have this model defined via torchvision, so we don't need to construct it from scratch ourselves. It's also possible to request that PyTorch download and populate the model with weights determined from extensive training on ImageNet, though we won't do that here, because we'll be using a slightly different set of weights to get started.\n",
    "\n",
    "The following cell sets up the standard ResNet18 model and provides a summary description. As you can see, even the smallest ResNet has a large number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60c436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tv.models.resnet18(pretrained=False)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c61eff",
   "metadata": {},
   "source": [
    "A network has already been pretrained on charged current interactions that will form the base network that you will modify and tune throughout the tasks. However, if you tried to load the weights from this model now, it would fail. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df68dff6",
   "metadata": {},
   "source": [
    "In the cell below write code to modify the classifier layers of the ResNet such that it can classify two different types of interaction and display the updated model structure (Hint: arguments to constructors often translate directly to class member variables). Does it look right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b0ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK - Modify the network architecture here\n",
    "\n",
    "# Display the model\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b1afd5",
   "metadata": {},
   "source": [
    "Hopefully you have a correctly structured network now. When you run the cell below you should see a message like\n",
    "\n",
    "```\n",
    "<All keys matched successfully>\n",
    "```\n",
    "\n",
    "otherwise, you'll likely see an error message below that should provide a clue as to the problem.\n",
    "\n",
    "You will modify and tune this network throughout the tasks. To get started, you'll find the `model_baseline.pt` file in **shared location directory**, which will need to be uploaded to Google Colab.\n",
    "\n",
    "We can load this model onto the GPU via the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4bc90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model_baseline.pt'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(filename, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca3a5e7",
   "metadata": {},
   "source": [
    "At this stage you have a two class classification ResNet with weights that have been set based on training on a number of charged current interactions, in particualr CCQE and CCRes. We want to add NCQE and NCRes to the interactions that can be classified, but we don't want to retrain the whole network.\n",
    "\n",
    "Your next subtask is to freeze the weights we've already loaded, so that they can't be modified. In the cell below, write some code to freeze all of the parameters in our model - you don't need to be subtle about this, we'll further modify the network in a future step that will allow the classification layer to be trained.\n",
    "\n",
    "A couple of useful methods/variables: classes that inherit from nn.Module (which model does) have a `parameters()` method returning a iterable collection of model parameter objects. Among the member variables of a parameter object is `requires_grad` (in order for a weight to be trainable it must be possible to compute a gradient for back propagation). Investigate these methods and variables and freeze the weights.\n",
    "\n",
    "You may find the `print_parameters(model)` method useful here, as it tells you which parameters of the model are trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7d336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK - Freeze all of the weights in your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196a8561",
   "metadata": {},
   "source": [
    "Obviously, a network with frozen weights can't be trained, so let's make the network trainable by modifying it so that it no longer has two classification outputs, but the four that we need for CCQE, CCRes, NCQE  and NCRes.\n",
    "\n",
    "This step is very similar to the one you performed above to permit the loading of the pretrained model, and so represents a good opportunity to refactor the code you wrote earlier into a method that can provide the required functionality for any nuumber of classes.\n",
    "\n",
    "Aside: Jupyter notebooks are great for this kind of fast prototyping work, but they can lead to bad habits in \"organising\" your code into cells with lots of repetition - don't write the same code repeatedly, if something is obviously and trivially reusable, write a method (or class). You may ultimately want to factor highly generic code out into libraries in separate Python modules.\n",
    "\n",
    "If you didn't write a function to do this earlier, a suggested method interface is given below. Note that `pass` is equivalent to a Python Todo message, replace this with your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223ca133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK - Modify the network architecture\n",
    "def model_reshape(model, target_num_classes):\n",
    "    \"\"\"Reshapes the model\n",
    "\n",
    "        Args:\n",
    "            model: The model to be reshaped\n",
    "            target_num_classes: The number of outputs required from the network\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812d6151",
   "metadata": {},
   "source": [
    "You should now have a network with the correct structure, with most of the weights set by the pretrained model that we've provided for you. Before we can train this updated model, we'll set up the datasets, dataloaders and transforms required. You don't need to edit anything, we've supplied this for you because it would likely take too long to correctly implement these steps from scratch, but you may want to take a look at `data_utils.py` and `training_utils.py` to see how datasets and dataloaders are created in this case (the code is neither particularly long, nor overly complex, but there are a number of subtle details).\n",
    "\n",
    "To briefly describe what is going on, the original ResNet18 was trained on a very particular dataset, with mandated input image size and a particular distribution of pixel values which need to be respected during transfer learning - the transforms used here ensure the input images conform to those specifications. In addition, to enhance generalisability, the images are randomly flipped about the beam axis in the training set, so the inputs in each training iteration are different.\n",
    "\n",
    "The datasets constructed simply split the event images into separate training and validation sets and provide the standard accessor methods that allow individual images (and associated true classification) to be loaded. The dataloaders are standard PyTorch dataloaders, splitting the respective training and validation sets into batches, with images in the training set being shuffled, so the network updates its knowledge based on images presented in a different order in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695fd57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 4\n",
    "\n",
    "transform = get_resnet_transforms()\n",
    "training_set, validation_set = make_datasets(f\"images\", transform, valid_size=10000, train_size=8000)\n",
    "dataloaders, dataset_sizes, weights = prepare_dataloaders(training_set, validation_set, batch_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0dd6b",
   "metadata": {},
   "source": [
    "Now you can begin updating this model to classify neutral current events as well. Below we've provided a template training loop that you should augment to perform the training steps.\n",
    "\n",
    "The method takes all of the arguments that we believe are required for this task, though feel free to extend or alter this to suit your needs (for example, it is not necessary to include a learning rate scheduler, but perhaps you think one might be useful).\n",
    "\n",
    "You'll also note some summary information in the comments belowing regarding what each argument contains. Note in particular that the data loaders for the training and validation sets are accessible via the dicctionary keys 'train' and 'val' respectively.\n",
    "\n",
    "Parts of the code with comments starting `# TASK` indicate those sections of code that require completion, but feel free to edit the surrounding code if it suits your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm\n",
    "\n",
    "def train_model(model, epochs, criterion, optimizer, dataloaders, dataset_sizes, device, output_filename):\n",
    "    \"\"\"Runs the training loop for a model\n",
    "\n",
    "        Args:\n",
    "            model: The model to be trained\n",
    "            epochs: The number of epochs to train for\n",
    "            criterion: The loss function to be optimised\n",
    "            optimizer: The optimizer to use\n",
    "            dataloaders: A dictionary containing the training ('train') and validation ('val') data loaders\n",
    "            dataset_sizes: The number of samples in the training ('train') and validation ('val') datasets\n",
    "            device: The device on which training should be run\n",
    "            output_filename: The output model filename\n",
    "        \n",
    "        Returns:\n",
    "            A tuple containing the best model and the metric history\n",
    "    \"\"\"\n",
    "    # initialise a map to hold the training statistics generate throughout training\n",
    "    statistics = {\n",
    "        'train': { 'loss': [], 'accuracy': [], 'f1': [] },\n",
    "        'val': { 'loss': [], 'accuracy': [], 'f1': [] }\n",
    "    }\n",
    "\n",
    "    epoch = 1\n",
    "    learning = True\n",
    "    while learning:\n",
    "        for phase in ['train', 'val']:\n",
    "            # TASK - Set the model to training or evaluation mode according to the current phase\n",
    "\n",
    "            # Initialise variables used to calculate statistics for each epoch\n",
    "            predictions = [None] * len(dataloaders[phase])\n",
    "            truths = [None] * len(dataloaders[phase])\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # iterate over the batches in the current dataloader\n",
    "            for b, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "                # TASK - transfer the inputs and the labels to the GPU\n",
    "\n",
    "                # TASK reset the gradients tracked by the optimizer\n",
    "\n",
    "                # operations on the model should compute and track gradients during training, but not during validation\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # TASK - run the network over the input images\n",
    "                    # The first time you run this you may want to print the result to see\n",
    "                    # if the output has the form you expect\n",
    "                    \n",
    "                    # TASK - compute the loss for the network classification\n",
    "                    \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # TASK - perform the back propagation step and update the optimizer\n",
    "                    # Should these steps always run?\n",
    "\n",
    "                    predictions[b] = preds\n",
    "                    truths[b] = labels.data\n",
    "\n",
    "                # Keep track of the running loss, factoring batch size - the final batch can sometimes be smaller than\n",
    "                # the specified batch size, so we need to account for that to ensure a correct loss for each epoch\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # calculate the loss, accuracy and f1 score for the epoch (stored in statistics)\n",
    "            update_statistics(statistics[phase], running_loss / dataset_sizes[phase], predictions, truths)\n",
    "            # print the statistics for the epoch\n",
    "            print_statistics(statistics, phase, epoch)\n",
    "\n",
    "        print()\n",
    "        epoch += 1\n",
    "        if epoch > epochs:\n",
    "            learning = False\n",
    "\n",
    "    # save the model\n",
    "    save_model(model, f\"{output_filename}\")\n",
    "\n",
    "    return model, statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ebc723",
   "metadata": {},
   "source": [
    "The code above simply defines the steps to be taken during training and validation. Now we need to actually exectue this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5b697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_parameters(model)\n",
    "model = model.to(device)\n",
    "\n",
    "# TASK - create a CrossEntropyLoss loss module here, and get it to use the weights returned by prepare_dataloaders\n",
    "\n",
    "# TASK - create an SGD optimizer module here\n",
    "\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "# TASK - call your model training method here, you might want to try just 1 epoch to begin with\n",
    "# we suggest you ultimately limit the number of epochs to 5-10\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "print(f\"Network {iter} trained in {t1 - t0} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a33268",
   "metadata": {},
   "source": [
    "Congratulations, you've now training a neutrino interaction classifier using transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee81fefa",
   "metadata": {},
   "source": [
    "# Task 2: Assessing the performance\n",
    "\n",
    "(See Slide 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db73aef",
   "metadata": {},
   "source": [
    "Having trained a network, we now want to start assessing its performance in a little more detail.\n",
    "\n",
    "You can already see a quantification of the overall network accuracy from the statistics printed at the end of each epoch (how did the network do? Are you impressed? Under-whelmed?), but this folds the performance of the different classes together and reports a single figure of merit.\n",
    "\n",
    "What we'd like you to do now is determine per class accuracies in the validation set and also produce a *confusion matrix* (if you're not familiar with confusion matrices this is just a table presenting the number of instances of a given true class against the network classification).\n",
    "\n",
    "Do the errors in the confusion matrix make sense?\n",
    "\n",
    "We're not going to provide a code template here (apart from a small note below), but much of the code you will require to run network inference on the validation set and extract network classification and truth information already exists above. In addition, you may want to identify some events of interest and produce an event display to see if that helps you understand where the network might have gone wrong.\n",
    "\n",
    "## Displaying events\n",
    "\n",
    "With a little bit of tensor manipulation you can display an event using the matplotlib imshow function (there are other approaches, but this is a relatively simple, low effort approach. Note that when you iterate through a dataset you are getting a batch of 128 events with each iteration, in particular each batch is of the form (inputs, labels), where inputs will in turn have the shape \\[128, 3, 224, 224\\]. If you want to access a particular event, you can just index into the first dimension of the tensor, which will then present a tensor with the shape \\[3, 224, 224\\]. The first dimension here represents the U (0), V (1) and W (2) views onto the event, so if you want to display the W view of event 73 in the current batch, you can simply use\n",
    "\n",
    "```\n",
    "plt.imshow(inputs[73][2])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92bb328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK - assess the network performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2a7b07",
   "metadata": {},
   "source": [
    "# Task 3: Finetuning the network\n",
    "(See Slide 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9776ad0",
   "metadata": {},
   "source": [
    "The first step to finetuning the network is to allow the weights that you have previously frozen to be modifiable again. Recall from earlier that you froze the weights using the `requires_grad`, depending on how general the function you wrote to perform that task was, you may be able to reuse it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ccd927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK - Allow all parameters of the network to be modifiable\n",
    "\n",
    "# You can check that the model has now frozen weights based on the output of print_parameters\n",
    "print_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916c0021",
   "metadata": {},
   "source": [
    "If all of your model parameters are modifiable, you can now continue training. You should be able to reuse `train_model` here (remember to change the output filename), but you may want to consider altering the learning rate of the optimiser. Try a few different values to see if it affects the behaviour - remember `train_model` saved your model from the previous stage so you can always reload it to ensure fair comparisons between runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ca876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK - continue training your saved network, comparing a few different learning rate settings for the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb2f31f",
   "metadata": {},
   "source": [
    "# Task 4: Assessing the performance\n",
    "(See Slide 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3343fa8f",
   "metadata": {},
   "source": [
    "Repeat Task 2 using the best trained network you produced from Task 3. How does the performance compare to that in Task 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778732c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK - assess the network performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
